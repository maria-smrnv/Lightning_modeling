import numpy as np
from scipy import sparse
from functools import reduce
from scipy.ndimage import binary_dilation
from time import time
from go_parallelizer import GoParallelizer

gp = GoParallelizer()

def datdot(A, B): # Произведение матриц A и B 
    now = time()

    res = A.dot(B)

    # Если В - вектор
    if len(B.shape) == 1:
        datdot.veccount += 1
        datdot.vectime += time() - now

    # Если В - матрица
    if len(B.shape) != 1: 
        datdot.matcount += 1
        datdot.mattime += time() - now

    return res

datdot.mattime = 0 # Суммарное время выполнения матричных операций
datdot.matcount = 0 # Суммарное количество выполнения матричных операций
datdot.vectime = 0 # Суммарное время выполнения векторных операций
datdot.veccount = 0 # Суммарное количество выполнения векторных операций

"""
Генерирует эволюцию "сферической фронтальной" области на основе потенциала и уравнения Лапласа.

Параметры:
b (ndarray): Начальная структура (например, сетка или карта).
eta (float): Параметр, определяющий чувствительность 
             роста к потенциальной разнице.
max_n (int): Максимальное количество итераций.

Возвращает массив:
    Phi2s - Список значений потенциала после изменения граничных значений (для анимации).
"""

def modulation(b, eta, max_n=1000):
    b = b.copy()  # Создаем копию исходного массива b, чтобы избежать изменений исходных данных.
    f = np.zeros_like(b.flatten())  # Создаем массив f с нулями, той же формы, что и b.
    L = lapl(b.shape)  # Генерируем оператор Лапласа для текущей формы b.

    # Функция для решения уравнения Лапласа с методом предобусловленного сопряженного градиента.
    solve = lambda B, U: solve_lapl(B, f, L, x0=U, method='ipcg')

    Phis, bs = [], [b]  # Списки для хранения значений потенциала, текущих значений и состояний b.
    Phi2s = []  # Список для хранения второго набора решений потенциала.

    # Цикл по итерациям (до max_n раз).
    for _ in range(max_n):
        b = bs[-1].copy()  # Берем текущее состояние из списка состояний.

        # Если Phis пуст, то предыдущий потенциал будет равен None, иначе берем последний элемент.
        prev = Phis[-1].flatten() if Phis else None
        
        # Решаем уравнение Лапласа для текущего состояния b.
        Phi = solve(b, prev).reshape(b.shape)
        
        # Применяем граничные условия: если в b есть NaN, сохраняем значения из b.
        Phi = np.where(~np.isnan(b), b, Phi)

        # Модифицируем b, добавляя граничные условия для первого и последнего столбца.
        b2 = b.copy()
        b2[:, [0, -1]] = 1
        
        # Решаем уравнение Лапласа для измененного b (с новыми граничными значениями).
        Phi2 = solve(b2, Phi2s[-1].flatten() if Phi2s else None).reshape(b.shape)
        
        # Применяем граничные условия для Phi2.
        Phi2 = np.where(~np.isnan(b2), b2, Phi2)
        
        # Добавляем Phi2 в список.
        Phi2s.append(Phi2)

        # Вычисляем точку роста на основе потенциала с параметром eta (умножение на потенциал).
        growth = add_point(Phi, eta, force_pos=True)

        # Если точка роста уже принадлежит границе (значение в b равно 1), завершаем цикл.
        if b[growth] == 1:
            break

        # Если нет, добавляем точку роста в структуру.
        b[growth] = 0

        # Добавляем обновленную структуру b в список состояний.
        bs.append(b)

        # Обновляем потенциал с учетом новых значений.
        Phis.append(np.where(~np.isnan(b), b, Phi))

    # Возвращаем массив: Phi2s (второй набор потенциалов).
    return np.array(Phi2s, dtype=float)

# Генерирация многомерный оператор Лапласа для сетки
def lapl(shape, mul=1, h=1):
    diags = [1, -2, 1]  # Значения для диагоналей 1D-матрицы Лапласа
    ks = [mul, 0, -mul]  # Индексы диагоналей для вышеуказанных значений
    
    # Создание 1D-матриц Лапласа T_j для каждой размерности
    Ts = [sparse.diags(diags, ks, shape=(j, j), format='csr') for j in shape]
    
    # Вычисление кронекеровского произведения (сумма тензорных произведений T_a, I_b и тензорное произведение I_a, T_b)
    return reduce(lambda a, b: sparse.kronsum(a, b, format='csr'), Ts[::-1]) / h

# Решение уравнения L*x=f с граничными условиями
def solve_lapl(bound, f, L, x0=None, solve_knowns=True, method='iccg'):
    f = f.copy()  # Копируем вектор правых частей, чтобы не изменять исходный
    bound_flat = bound.flatten()  # Преобразуем граничные условия в одномерный массив
    bn = np.nan_to_num(bound_flat)  # Заменяем NaN на 0 в граничных условиях
    f += datdot(L, bn)  # Добавляем влияние известных значений в правую часть f
    
    unknown = np.isnan(bound_flat).astype(int)  # Определяем, какие элементы неизвестны (NaN)
    known_idx = np.where(1 - unknown)  # Индексы известных значений
    solve_idx = np.where(unknown)  # Индексы неизвестных значений
    f[known_idx] = bound_flat[known_idx]  # Подставляем известные значения в f
    
    # Если флаг solve_knowns установлен в True, оставляем уравнения для известных переменных
    if solve_knowns:
        keep_rows = sparse.diags(unknown)  # Создаем матрицу для известных переменных
        L = datdot(datdot(keep_rows, L), keep_rows) - sparse.diags(1 - unknown)  # Обновляем матрицу L
        solve_idx = np.indices(bound_flat.shape)  # Получаем индексы для всех элементов
    
    i = solve_idx[0]  # Индексы, где нужно решить уравнение
    x0 = bn if x0 is None else x0  # Инициализация начального приближения
    bound_flat[i] = solve_poisson(L[i[:, None], i], -f[i], x0=x0[i])  # Решаем уравнение Пуассона для неизвестных значений
    
    return bound_flat.reshape(bound.shape)  # Возвращаем результат в исходной форме (с учетом формы входного массива)

# Моделирование случайного выбора точки на границе роста области A
def add_point(A, eta, force_pos=False):
    # Находим границу роста: это все точки, которые окружены нулями в массиве A
    # Для этого используем бинарную дилатацию (расширение) и XOR с исходным состоянием массива
    frontier = binary_dilation(A == 0) ^ (A == 0)
    
    # Получаем индексы элементов, которые являются частью границы роста
    frontier_idx = np.where(frontier)
    
    # Рассчитываем потенциалы для каждой точки на границе: A[frontier_idx] - значения на границе, возведенные в степень eta
    phis = A[frontier_idx] ** eta
    
    # Если задан параметр force_pos, все отрицательные значения потенциалов заменяются на 0 (гарантируем положительные потенциалы)
    phis = phis if not force_pos else np.maximum(phis, 0)
    
    # Нормализуем потенциалы, чтобы получить вероятности (сумма вероятностей = 1)
    probs = phis / np.sum(phis)
    
    # Создаем список индексов (координат) точек на границе
    idxs = list(zip(*frontier_idx))
    
    # Выбираем случайный индекс из списка idxs с вероятностями, пропорциональными значению phis
    # Это значит, что точки с большими потенциалами будут иметь больше шансов быть выбранными
    return idxs[np.random.choice(len(idxs), p=probs)]

# Решение уравнение Пуассона Lx=f
def solve_poisson(L, f, x0):
    pc = IP_precond  # Использование предварительного условия из функции IP_precond
    return pcg(x0, f, L, pc(L))  # Решение через метод сопряженных градиентов (PCG) с предобуславливанием

# Возвращает функцию для решения Lx = f в pcg с неполным пуассоновским предусловием
def IP_precond(A):
    L = sparse.tril(A)  # Извлечение нижней треугольной матрицы из A
    D = sparse.diags(1 / A.diagonal())  # Диагональная матрица, инвертированная из диагонали A
    K = sparse.eye(A.shape[0]) - datdot(L, D)  # Калькуляция K = I - L * D
    Minv = datdot(K, K.T)  # Матричный предобуславливатель Minv = K * K^T
    return lambda r: datdot(Minv, r)  # Функция для решения


# Метод сопряженных градиентов с предусловием (PCG)
def pcg(x, b, A, get_z, min_err=1e-7):
    # Время начала вычислений для анализа
    now = time()
    
    # 1. Расчет начальной остаточной ошибки r = b - A*x
    r = b - datdot(A, x)  # Вычисление остаточной ошибки
    pcg.dot += time() - now  # Время, затраченное на вычисление dot-операции (умножение A на x)
    pcg.dotShape.add((A.shape, x.shape))  # Добавление формы матрицы A и вектора x для статистики
    now = time()
    
    # 2. Получение преобразования остаточной ошибки с помощью предусловия
    z = get_z(r)  # z = M^(-1) * r, где M - матрица, применяемая в качестве предусловия
    pcg.get_z += time() - now  # Время, затраченное на вычисление get_z
    p = z  # Начальное направление p устанавливается равным z
    
    # 3. Вычисление скалярного произведения z^T * r для дальнейшего использования в процессе итераций
    now = time()
    zr = z.T @ r  # Скалярное произведение z и r
    pcg.at += time() - now  # Время, затраченное на вычисление скалярного произведения
    
    # 4. Начало итеративного процесса
    while True:
        # Условие останова: если значение zr (скалярное произведение) меньше минимальной ошибки, завершить
        if np.abs(zr) < min_err:
            break
        
        # Защита от деления на ноль
        if zr == 0:
            zr = 1e-20  # Если zr равно 0, заменяем его на очень маленькое значение
            print("changed zr")  # Логирование изменения zr для предотвращения деления на ноль
        
        # 5. Вычисление Ap (A * p), где p - текущее направление
        now = time()
        Ap = datdot(A, p)  # Умножение матрицы A на вектор p
        pcg.dot += time() - now  # Время, затраченное на умножение
        pcg.dotShape.add((A.shape, p.shape))  # Добавление формы матрицы A и вектора p для статистики
        
        # 6. Вычисление скалярного произведения p^T * Ap
        now = time()
        pAp = p.T @ Ap  # Скалярное произведение p и Ap
        pcg.at += time() - now  # Время, затраченное на вычисление p^T * Ap
        
        # Защита от деления на ноль
        if pAp == 0:
            pAp = 1e-20  # Если pAp равно 0, заменяем его на очень маленькое значение
        
        # 7. Вычисление альфа (шаг)
        alp = zr / pAp  # Шаг альфа, пропорциональный скалярному произведению zr и pAp
        
        # 8. Обновление решения x и остаточной ошибки r
        gp.datadd(x, p, alp, x)  # Обновление решения: x = x + alp * p
        gp.datsub(r, Ap, alp, r)  # Обновление остаточной ошибки: r = r - alp * Ap

        # 9. Пересчитываем z с использованием нового остаточного вектора r
        now = time()
        z = get_z(r)  # Получаем новое значение z для обновленного r
        pcg.get_z += time() - now  # Время, затраченное на вычисление нового z
        
        # 10. Вычисление коэффициента бета для обновления направления p
        now = time()
        beta = z.T @ r / zr  # Вычисление коэффициента бета для обновления направления
        pcg.at += time() - now  # Время, затраченное на вычисление бета
        
        # 11. Обновление направления p
        gp.datadd(z, p, beta, p)  # Обновление направления: p = z + beta * p
        
        # Обновление скалярного произведения zr для контроля сходимости
        zr *= beta  # Обновляем значение zr
        
    # 12. Возвращаем окончательное решение x
    return x

pcg.at = 0
pcg.dot = 0
pcg.get_z = 0
pcg.dotShape = set()